apply(x[10:18,],2,mean))
p <- sapply(1:100, function(x)
sum(boot_difference[[x]] >=
(mean(pop1mc[,x])-mean(pop2mc[,x]))))/10000
sum(p <= 0.05)/100
print(power)
power <- sum(p <= 0.05)/100
print(power)
print(power1)
power1 <- sum(p <= 0.05)/100
print(power1)
rep_samps <- replicate(10000, rnorm(27, mean=62.9, sd=13.3))
rep_means <- apply(rep_samps2,2,mean)
rep_sd <- apply(rep_samps2,2,function(x)sd(x))
t_scores <- (rep_means2-62)/(rep_sd2/sqrt(27))
t_rejection <- sapply(t_scores2,function(x)>=qt(.95, df=27))
rep_samps <- replicate(10000, rnorm(27, mean=62.9, sd=13.3))
rep_means <- apply(rep_samps2,2,mean)
rep_sd <- apply(rep_samps2,2,function(x)sd(x))
t_scores <- (rep_means2-62)/(rep_sd2/sqrt(27))
t_rejection <- sapply(t_scores2,function(x)(x)>=qt(.95, df=27))
reject_2 <- sum(t_rejection)
print(reject_2/10000)
efs <- (62.9-62)/13.3
print(efs)
rep_samps2 <- replicate(10000,
rnorm(1352,
mean=62.9,
sd=13.3))
rep_means2 <- apply(rep_samps2,2,mean)
rep_sd2 <- apply(rep_samps2,2,function(x)sd(x))
t_scores2 <- (rep_means2-62)/(rep_sd2/sqrt(1352))
t_rejection2 <- sapply(t_scores2,
function(x)(x)>=qt(.95,
df=1352))
reject_2 <- sum(t_rejection2)
print(reject_2/10000)
rep_samps <- replicate(10000, rnorm(27, mean=62.9, sd=13.3))
rep_means <- apply(rep_samps,2,mean)
rep_sd <- apply(rep_samps,2,function(x)sd(x))
t_scores <- (rep_means-62)/(rep_sd/sqrt(27))
t_rejection <- sapply(t_scores,function(x)(x)>=
qt(.95, df=27))
reject <- sum(t_rejection)
print(reject/10000)
## Register data
rpA <- c(5.8, 1, 1.1, 2.1, 2.5, 1.1, 1, 1.2, 3.2, 2.7)
rpB <- c(1.5, 2.7, 6.6, 4.6, 1.1, 1.2, 5.7, 3.2, 1.2, 1.3)
## Conduct the test
wilcox.test(rpA, rpB, alternative="two.sided")
wilcox.test(rpA, rpB, alternative="two.sided", exact=FALSE)
wilcox.test(rpA, rpB, alternative="two.sided", exact=FALSE, correct=FALSE)
## Test statistic calculation
rpA.data <- data.frame(time=rpA, person="A")
rpB.data <- data.frame(time=rpB, person="B")
rp.data <- rbind(rpA.data, rpB.data)
rp.data$rank <- rank(rp.data$time)
rp.data
sums <- tapply(rp.data$rank, rp.data$person, sum)
sums
nA <- length(rpA)
nB <- length(rpB)
min(tsA,tsB)
tsA <- nA*nB + (nA*(nA+1)/2) - sums[1]
tsB <- nA*nB + (nB*(nB+1)/2) - sums[2]
min(tsA,tsB)
## Create two-way table for 114 individuals' hair and eye color
M <- matrix(c(38,14,11,51), nrow=2, ncol=2)
dimnames(M) <- list(Hair=c("Fair","Dark"), Eye=c("Blue","Brown"))
M
## Create a two-way table for 400 individuals' gender and education
L <- matrix(c(63,42,54,44,46,53,41,57), nrow=2, ncol=4)
dimnames(L) <- list(Gender=c("Female","Male"),
Education=c("HS","BA","MA","PhD"))
L
sum(L)
## Joint distribution in proportions
Lp <- prop.table(L)
sum(Lp)
## Conditional distributions of education levels
L.cond.edu <- prop.table(L,2)
L.cond.edu
apply(L.cond.edu,2,sum)
apply(L.cond.edu,2,sum)
L.cond.edu
## Joint distribution in proportions
Lp <- prop.table(L)
sum(Lp)
Lp
### IN CLAS ###
library(ggplot2)
k <- 10000
n <-7
ps <- 0.3
mu <- n * ps
ggplot(df, aes(x=sampes)) + geom_histogram(binwidth = 1, aes(y=..density..), colour="black", fill="white") + stat_function(fun=dnorm, args=list(mean=mu, sd=sigma))
k <- 10000
n <-7
ps <- 0.3
mu <- n * ps
sigma <- sqrt(n*ps*(1-ps))
df <- data.frame(samps=rbinom(n=k, size=n, probs=ps))
ggplot(df, aes(x=sampes)) + geom_histogram(binwidth = 1, aes(y=..density..), colour="black", fill="white") + stat_function(fun=dnorm, args=list(mean=mu, sd=sigma))
df <- data.frame(samps=rbinom(n=k, size=n, probs=ps))
ggplot(df, aes(x=samps)) +
geom_histogram(binwidth = 1, aes(y=..density..), colour="black", fill="white") +
stat_function(fun=dnorm, args=list(mean=mu, sd=sigma))
df <- data.frame(samps=rbinom(n=k, size=n, probs=ps))
k <- 10000
n <-7
ps <- 0.3
mu <- n * ps
sigma <- sqrt(n*ps*(1-ps))
df <- data.frame(samps=rbinom(n=k, size=n, probs=ps))
df <- data.frame(samps=rbinom(n=k, size=n, prob=ps))
ggplot(df, aes(x=samps)) +
geom_histogram(binwidth = 1, aes(y=..density..), colour="black", fill="white") +
stat_function(fun=dnorm, args=list(mean=mu, sd=sigma))
ps <- 0.1
mu <- n * ps
sigma <- sqrt(n*ps*(1-ps))
df <- data.frame(samps=rbinom(n=k, size=n, prob=ps))
ggplot(df, aes(x=samps)) +
geom_histogram(binwidth = 1, aes(y=..density..), colour="black", fill="white") +
stat_function(fun=dnorm, args=list(mean=mu, sd=sigma))
n <-28
ps <- 0.1
mu <- n * ps
sigma <- sqrt(n*ps*(1-ps))
df <- data.frame(samps=rbinom(n=k, size=n, prob=ps))
ggplot(df, aes(x=samps)) +
geom_histogram(binwidth = 1, aes(y=..density..), colour="black", fill="white") +
stat_function(fun=dnorm, args=list(mean=mu, sd=sigma))
n <-49
ps <- 0.1
mu <- n * ps
sigma <- sqrt(n*ps*(1-ps))
df <- data.frame(samps=rbinom(n=k, size=n, prob=ps))
ggplot(df, aes(x=samps)) +
geom_histogram(binwidth = 1, aes(y=..density..), colour="black", fill="white") +
stat_function(fun=dnorm, args=list(mean=mu, sd=sigma))
n <-70
ps <- 0.1
mu <- n * ps
sigma <- sqrt(n*ps*(1-ps))
df <- data.frame(samps=rbinom(n=k, size=n, prob=ps))
ggplot(df, aes(x=samps)) +
geom_histogram(binwidth = 1, aes(y=..density..), colour="black", fill="white") +
stat_function(fun=dnorm, args=list(mean=mu, sd=sigma))
n <-28
ps <- 0.1
mu <- n * ps
sigma <- sqrt(n*ps*(1-ps))
df <- data.frame(samps=rbinom(n=k, size=n, prob=ps))
ggplot(df, aes(x=samps)) +
geom_histogram(binwidth = 1, aes(y=..density..), colour="black", fill="white") +
stat_function(fun=dnorm, args=list(mean=mu, sd=sigma))
n <-49
ps <- 0.1
mu <- n * ps
sigma <- sqrt(n*ps*(1-ps))
df <- data.frame(samps=rbinom(n=k, size=n, prob=ps))
ggplot(df, aes(x=samps)) +
geom_histogram(binwidth = 1, aes(y=..density..), colour="black", fill="white") +
stat_function(fun=dnorm, args=list(mean=mu, sd=sigma))
k <- 10000
n <-49
ps <- 0.1
mu <- n * ps
sigma <- sqrt(n*ps*(1-ps))
df <- data.frame(samps=rbinom(n=k, size=n, prob=ps))
ggplot(df, aes(x=samps)) +
geom_histogram(binwidth = 1, aes(y=..density..), colour="black", fill="white") +
stat_function(fun=dnorm, args=list(mean=mu, sd=sigma))
n <-70
ps <- 0.1
mu <- n * ps
sigma <- sqrt(n*ps*(1-ps))
df <- data.frame(samps=rbinom(n=k, size=n, prob=ps))
ggplot(df, aes(x=samps)) +
geom_histogram(binwidth = 1, aes(y=..density..), colour="black", fill="white") +
stat_function(fun=dnorm, args=list(mean=mu, sd=sigma))
## Conduct the test
phat <- c(0.117, 0.121)
n <- c(50000, 60000)
x <- phat*n
z2.prop <- prop.test(x, n, alternative="two.sided", correct=FALSE)
z2.prop
## Determine test statistic
comb.phat <- sum(x)/sum(n)
z <- diff(phat)/sqrt(comb.phat*(1-comb.phat)*(1/n[1]+1/n[2]))
z
## Determine p-value
p.value <- 2*(1-pnorm(z))
p.value
## Compare test statistic and p-value to output
sqrt(z2.prop$statistic)
z2.prop$p.value
z1.prop <- prop.test(x, n, alternative="one.sided", correct=FALSE)
z1.prop <- prop.test(x, n, alternative="less", correct=FALSE)
z1.prop$p.value
## Calculate the power
library(pwr)
pwr.chisq.test(w=0.3, N=400, df=3, sig.level=0.05)
## Determine the sample size required for power of 0.8
pwr.chisq.test(w=0.3, df=3, sig.level=0.05, power=0.8)
## Calculate the power
pwr.chisq.test(w=0.1, N=200, df=3, sig.level=0.05)
## Determine the sample size required for power of 0.8
pwr.chisq.test(w=0.1, df=3, sig.level=0.05, power=0.8)
## Calculate the power
pwr.chisq.test(w=0.1, N=200, df=3, sig.level=0.05)
## Determine the sample size required for power of 0.8
pwr.chisq.test(w=0.1, df=3, sig.level=0.05, power=0.8)
## Calculate the power
pwr.p.test(h=-0.2, n=100, sig.level=0.05, alternative="less")
## Determine the sample size required for power of 0.8
pwr.p.test(h=-0.2, sig.level=0.05, power=0.8, alternative="less")
#starting to look at pipelines
library(tidyverse)
salary_games_info <- read_csv('Lect2data.csv')
head(salary_games_info)
##############################################################
##############################################################
################### Ceci n'est pas une pipe ##################
##############################################################
##############################################################
salary_games_info %>% head()
salary_games_info %>% head() %>% tail(3)
tail(head(salary_games_info), 3)
salary_small_save <- salary_games_info %>% head() %>% tail(3)
##############################################################
##############################################################
######################## SUMMARIZE ###########################
##############################################################
##############################################################
salary_games_info %>%
summarize(count=n())
salary_games_info %>%
summarize(average_salary=mean(salary))
salary_games_info %>% summary()
salary_games_info %>%
summarize(average_salary=mean(salary)) %>% is_tibble()
salary_games_info %>% summary() %>% is_tibble()
##############################################################
##############################################################
########################## FILTER ############################
##############################################################
##############################################################
salary_games_info %>% filter(yearID > 1986 & yearID <= 2000)
salary_games_info %>% filter(yearID > 1986 & yearID <= 2000) %>% tail()
##############################################################
##############################################################
######################### ARRANGE ############################
##############################################################
##############################################################
salary_games_info %>% filter(yearID > 1986 & yearID <= 2000) %>% arrange(desc(yearID))
salary_games_info %>% filter(yearID > 1986 & yearID <= 2000) %>% arrange(desc(yearID), salary)
##############################################################
##############################################################
######################## GROUP_BY ############################
##############################################################
##############################################################
salary_games_info %>%
group_by(playerID) %>%
summarize(count=n())
salary_games_info %>%
group_by(playerID) %>%
summarize(count=n()) %>%
arrange(desc(count))
salary_games_info %>%
group_by(playerID) %>%
summarize(numYearsPlayed = length(unique(yearID)), count=n())
salary_games_info %>%
group_by(playerID) %>%
arrange(yearID) %>%
mutate(yearContinuity = yearID - lag(yearID)) %>%
filter(yearID>1985)
##############################################################
##############################################################
######################### MUTATE #############################
##############################################################
##############################################################
salary_games_info %>% mutate(sqrt_games = sqrt(G))
salary_games_info %>% mutate(atbats_per_game = AB/G)
#starting to look at pipelines
library(tidyverse)
package.install(tidyverse)
install.packages(tidyverse)
install.packages(tidyverse)
install.package(tidyverse)
# goal is to get data into tidy format.
# often data is not tidy, so you have to do some work
# what is tidy data?
#     each variable has its own column
#     each observation gets its own row, and not multiple rows
#     one datapoint per cell
library(tidyverse)
data <- tibble(group = sample(c('red', 'green', 'blue'), 100, replace=TRUE),
`2011`=runif(100), `2012`=rnorm(100), `2013`=1:100)
data.tidy <- data %>% gather(key="year", value="measurement", -group)
data.tidy <- data %>% gather(key="year", value="measurement", -group) %>%
mutate(year=as.integer(year))
data <- tibble(observation=rep(1:10, each=3),
meas_var=rep(c('length', 'width', 'height'), times=10),
measurement=runif(30))
data.tidy <- data %>% spread(key="meas_var", value="measurement")
data.tidy
data <- tibble(group = sample(c('red', 'green', 'blue'), 100, replace=TRUE),
`2011`=runif(100), `2012`=rnorm(100), `2013`=1:100)
data
data.tidy <- data %>% gather(key="year", value="measurement", -group)
data.tidy
data.tidy <- data %>% gather(key="year", value="measurement", -group) %>%
mutate(year=as.integer(year))
data.tidy
View(data.tidy)
data <- tibble(observation=rep(1:10, each=3),
meas_var=rep(c('length', 'width', 'height'), times=10),
measurement=runif(30))
view(data)
View(data)
View(data)
data.tidy
View(data)
View(data.tidy)
data.tidy <- data %>% spread(key="meas_var", value="measurement")
data.tidy <- data %>% spread(key="meas_var", value="measurement")
View(data.tidy)
View(data)
library(tidyverse)
flights <- read_csv('flights_jan.csv')
flights %>% mutate("Weekend" = ((flights["DAY_OF_WEEK"] > 5) = 1)) %>% ggplot(aes(factor(Weekend), TAXI_OUT)) +  geom_violin()
flights %>% filter(DAY_OF_WEEK <= 5) %>% mutate("Weekday" = 1) %>%
ggplot(aes(factor(Weekday), TAXI_OUT)) +  geom_violin() +
geom_violin(draw_quantiles=c(.25, .5, .75), scale="count")
flights %>% filter(DAY_OF_WEEK <= 5) %>% mutate("Weekday" = 1) %>%
ggplot(aes(factor(Weekday), TAXI_OUT)) +  geom_violin() +
geom_violin(draw_quantiles=c(.25, .5, .75), scale="count")
#Your client would like to understand the differences in the distributions of taxi times between weekends
#and weekdays (they don't care so much about what day it is, but just if it is a weekday or weekend).
#Further, your client is interested in seeing this across different airlines.
#Create a single visualization using a single pipeline that can do this.  As a further challenge,
#your client would like to see the airlines listed in order of the volume of flights, with the
#airline flying the most flights listed first.
#In creating your visualiztion, you should focus on clarity.  While not enough information is obviously
#not ideal, too much information can be confusing.  You should think about the balance between being
#informative about the distrubutions but sensitive to the fact that you are comparing across many distributions.
#this should be done in a single pipeline.
library(tidyverse)
flights <- read_csv('flights_jan.csv')
flights %>% mutate("Weekend" = ((flights["DAY_OF_WEEK"] > 5) = 1)) %>% ggplot(aes(factor(Weekend), TAXI_OUT)) +  geom_violin()
flights %>% filter(DAY_OF_WEEK <= 5) %>% mutate("Weekday" = 1) %>%
ggplot(aes(factor(Weekday), TAXI_OUT)) +  geom_violin() +
geom_violin(draw_quantiles=c(.25, .5, .75), scale="count")
goalies %>%
filter(year > 2000) %>%
inner_join(master_file, by=c("playerID" = "playerID")) %>%
filter(birthYear < 1974) %>%
mutate(ratioGA = SA/GA) %>%
mutate(ratioPGA = PostSA/PostGA)%>%
group_by(playerID) %>%
arrange(playerID, desc(year))%>%
#mutate(yearContinuity = lag(year)) %>%
mutate(better = ratioGA/ratioPGA) %>%
#select(playerID, year, yearContinuity, ratioGA, ratioPGA, better) %>%
mutate(continuation = (lag(better) < better)) %>%
select(playerID, year, ratioGA, ratioPGA, better, continuation, tmID) %>%
filter(continuation == TRUE) %>%
distinct(playerID, tmID) %>%
inner_join(teamvteam, by=c("tmID"="tmID")) %>%
filter(year > 2000) %>%
filter(oppID == "PIT", W >=3) %>%
distinct(playerID, tmID, year) %>%
left_join(coaches, by= c("year"="year", "tmID" = "tmID")) %>%
distinct(tmID, year, coachID) %>%
left_join(master_file, by=c("coachID"="coachID", "playerID"="playerID"))
goalies %>%
filter(year > 2000) %>%
inner_join(master_file, by=c("playerID" = "playerID")) %>%
filter(birthYear < 1974) %>%
mutate(ratioGA = SA/GA) %>%
mutate(ratioPGA = PostSA/PostGA)%>%
group_by(playerID) %>%
arrange(playerID, desc(year))%>%
#mutate(yearContinuity = lag(year)) %>%
mutate(better = ratioGA/ratioPGA) %>%
#select(playerID, year, yearContinuity, ratioGA, ratioPGA, better) %>%
mutate(continuation = (lag(better) < better)) %>%
select(playerID, year, ratioGA, ratioPGA, better, continuation, tmID) %>%
filter(continuation == TRUE) %>%
distinct(playerID, tmID) %>%
inner_join(teamvteam, by=c("tmID"="tmID")) %>%
filter(year > 2000) %>%
filter(oppID == "PIT", W >=3) %>%
distinct(playerID, tmID, year) %>%
left_join(coaches, by= c("year"="year", "tmID" = "tmID")) %>%
distinct(tmID, year, coachID) %>%
left_join(master_file, by=c("coachID"="coachID", "playerID"="playerID"))
#please only load the tidyverse library
library(tidyverse)
master_file <- read_csv('Master.csv')
goalies <- read_csv('Goalies.csv')
coaches <- read_csv('Coaches.csv')
teamvteam <- read_csv('TeamVsTeam.csv')
#please only load the tidyverse library
library(tidyverse)
#please read in the files as below.  Your code must
#run and produce the result.  If your code does not
#run on the TAs computer your HW solution will not
#be accepted.
setwd("./")
master_file <- read_csv('Master.csv')
data_frame<-data.frame(data)
# setting data for testing and training
set.seed(1)
library(e1071)
library(ElemStatLearn)
library(kernlab)
library(gbm)
library(MASS)
library(glmnet)
library(kknn)
library(class)
library(deldir)
library(lars)
library(PerformanceAnalytics)
library(leaps)
library(ncvreg)
library(party)
library(rpart)
library(tree)
library(ipred)
library(rpart)
library(randomForest)
library(ggplot2)
library(caret)
library(graphics)
library(factoextra)
library(mclust)
set.seed(1)
setwd("/Users/maxryoo/Documents/Fall 2019/STAT 5630/Code/hw_last")
train = read.table("traindata.txt")
pca = prcomp(train[1:57], scale = TRUE)
plot(pca)
fviz_eig(pca)
summary(pca)
colnames(train)
cum_prop <- cumsum(pca$sdev^2 / sum(pca$sdev^2))
last_index = min(which(cum_prop > 0.90))
dr_data <- as.data.frame(pca$x[,1:last_index])
plot <- cbind(dr_data[,1],dr_data[,2], train$V58)
colnames(plot) <- c("PC1", "PC2", "Class")
ggplot(as.data.frame(plot)) +
geom_point(aes(PC1,PC2, color=factor(Class)), alpha=0.5) +
scale_color_manual(values=c("blue", "red")) + theme_bw() + labs(color="Spam")
## all variables
spam.kmeans.all <- kmeans(pca$x, centers = 2, nstart = 20, trace = TRUE)
spam.kmeans.all$centers
all_variables = cbind(as.data.frame(pca$x), train$V58)
colnames(all_variables) <- c(colnames(pca$x), "Class")
ggplot(all_variables, aes(PC1, PC2, color=factor(Class))) +
geom_point(alpha = 0.4, size = 3.5) + # true cluster
geom_point(col = c("blue", "red")[spam.kmeans.all$cluster]) +
scale_color_manual(values = c("blue", "red")) + theme_bw() +
ggtitle("Kmeans of all variables") + labs(color="Spam")
spam.kmeans.dr <- kmeans(dr_data, centers = 2, nstart = 20, trace = TRUE)
spam.kmeans.dr$centers
dr_variables = cbind(dr_data, train$V58)
colnames(dr_variables) <- c(colnames(dr_data), "Class")
ggplot(dr_variables, aes(PC1, PC2, color=factor(Class))) +
geom_point(alpha = 0.4, size = 3.5) + # true cluster
geom_point(col = c("blue", "red")[spam.kmeans.dr$cluster]) +
scale_color_manual(values = c("blue", "red")) + theme_bw() +
ggtitle("Kmeans of reduced variables") + labs(color="Spam")
spam.kmeans.two <- kmeans(plot[,1:2], centers = 2, nstart = 20, trace = TRUE)
spam.kmeans.two$centers
ggplot(as.data.frame(plot), aes(PC1, PC2, color=factor(Class))) +
geom_point(alpha = 0.4, size = 3.5) + # true cluster
geom_point(col = c("blue", "red")[spam.kmeans.two$cluster]) +
scale_color_manual(values = c("blue", "red")) + theme_bw() +
ggtitle("Kmeans of two variables") + labs(color="Spam")
#mclust
summary(Mclust(as.data.frame( cbind(dr_data[,1],dr_data[,2])), G =2), parameter=TRUE)
plot(Mclust(as.data.frame( cbind(dr_data[,1],dr_data[,2])), G =2), what="classification")
mclustering = Mclust(as.data.frame( cbind(dr_data[,1],dr_data[,2])), G =2)
data_mclust = mclustering$data
data_mclust_class = mclustering$classification
plot_mclust <- cbind(data_mclust, data_mclust_class, train$V58)
colnames(plot_mclust) = c("V1", "V2", "Class", "True")
ggplot(as.data.frame(plot_mclust), aes(V1, V2, color=factor(True))) +
geom_point(alpha = 0.4, size = 3.5) +
scale_color_manual(values = c("blue", "red")) +
geom_point(col = c("blue", "red")[as.data.frame(plot_mclust)$Class]) + theme_bw() +
ggtitle("MClustering") + labs(color="Spam")
mclustering = Mclust(as.data.frame( cbind(dr_data[,1],dr_data[,2])), G =2)
data_mclust = mclustering$data
data_mclust_class = mclustering$classification
plot_mclust <- cbind(data_mclust, data_mclust_class, train$V58)
colnames(plot_mclust) = c("V1", "V2", "Class", "True")
ggplot(as.data.frame(plot_mclust), aes(V1, V2, color=factor(True))) +
geom_point(alpha = 0.4, size = 3.5) +
scale_color_manual(values = c("blue", "red")) +
geom_point(col = c("blue", "red")[as.data.frame(plot_mclust)$Class]) + theme_bw() +
ggtitle("MClustering") + labs(color="Spam")
#
?mclust
#
?MClust
MClust
#
?Mclust
