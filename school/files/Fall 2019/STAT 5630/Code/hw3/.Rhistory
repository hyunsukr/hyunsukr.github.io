library(caret)
setwd("/Users/maxryoo/Documents/Fall 2019/STAT 5630/Code/hw3")
train = read.table("traindata.txt")
test = read.table("testdata.txt")
head(train)
traindata=train[,-58]
testdata=test[,-58]
## A
spamratio <- sum(train$V58==1)/length(train$V58)
# spam ration = 0.3973899
nospamration<- sum(train$V58==0)/length(train$V58)
# not spam ration = 0.6026101
print(c("Spam entry Proportion: ", spamratio))
print(c("Not Spam entry Proportion: ", nospamration))
## A
spamratio_test <- sum(test$V58==1)/length(test$V58)
# spam ration = 0.3973899
nospamration_test <- sum(test$V58==0)/length(test$V58)
# not spam ration = 0.6026101
print(c("Spam entry Proportion: ", spamratio_test))
print(c("Not Spam entry Proportion: ", nospamration_test))
## B
continous_columns = sum(sapply(train, class) == "numeric")
print(c("Continous Columns: ", continous_columns))
## "Continous Columns: " "55"
continous_names = colnames(train[, sapply(train, class) == "numeric"])
print(c("Continous Columns names: ", continous_names))
categorical = sum(sapply(train, class) != "numeric")
print(c("Categorical Columns: ", categorical))
## print(c("Categorical Columns: ", categorical))
categorical_names = colnames(train[, sapply(train, class) != "numeric"])
print(c("Categorical Columns names: ", categorical_names))
## MODEL AND ANALYSIS
### A
#LDA with V55-57
lda_55_57_test<-test[,c(55:57)]
lda.model = lda (V58 ~ V55 + V56 + V57, data=train)
lda_prediction = predict(lda.model, newdata=lda_55_57_test)
#accuracy
accuracy_lda = sum(test$V58 == lda_prediction$class)/length(test$V58)
#sensivity
total_spam_lda = sum(test$V58 == 1)
num_spam_correct_lda = sum((test$V58 == 1) & (lda_prediction$class == 1))
sensitivity_lda = num_spam_correct_lda/total_spam_lda
#specificity
total_non_spam_lda = sum(test$V58 == 0)
num_non_spam_correct_lda = sum((test$V58 == 0) & (lda_prediction$class == 0))
specificity_lda = num_non_spam_correct_lda / total_non_spam_lda
table_lda <- data.frame("Accuracy" = accuracy_lda, "Sensitivity" = sensitivity_lda, "Specificity" = specificity_lda)
print(table_lda)
#QDA with V55-57
qda_55_57_test<-test[,c(55:57)]
qda.model = qda (V58 ~ V55 + V56 + V57, data=train)
qda_prediction = predict(qda.model, newdata=qda_55_57_test)
#accuracy
accuracy_qda = sum(test$V58 == qda_prediction$class)/length(test$V58)
#sensivity
total_spam_qda = sum(test$V58 == 1)
num_spam_correct_qda = sum((test$V58 == 1) & (qda_prediction$class == 1))
sensitivity_qda = num_spam_correct_qda/total_spam_qda
#specificity
total_non_spam_qda = sum(test$V58 == 0)
num_non_spam_correct_qda = sum((test$V58 == 0) & (qda_prediction$class == 0))
specificity_qda = num_non_spam_correct_qda / total_non_spam_qda
table_qda <- data.frame("Accuracy" = accuracy_qda, "Sensitivity" = sensitivity_qda, "Specificity" = specificity_qda)
print(table_qda)
### B
#LDA with ALL
lda.model_all = lda (V58 ~., data=train)
lda_prediction_all = predict(lda.model_all, newdata=testdata)
#accuracy
accuracy_lda_all = sum(test$V58 == lda_prediction_all$class)/length(test$V58)
#sensivity
total_spam_lda_all = sum(test$V58 == 1)
num_spam_correct_lda_all = sum((test$V58 == 1) & (lda_prediction_all$class == 1))
sensitivity_lda_all = num_spam_correct_lda_all/total_spam_lda_all
#specificity
total_non_spam_lda_all = sum(test$V58 == 0)
num_non_spam_correct_lda_all = sum((test$V58 == 0) & (lda_prediction_all$class == 0))
specificity_lda_all = num_non_spam_correct_lda_all / total_non_spam_lda_all
table_lda_all <- data.frame("Accuracy" = accuracy_lda_all, "Sensitivity" = sensitivity_lda_all, "Specificity" = specificity_lda_all)
print(table_lda_all)
print("Difference in LDA")
print(table_lda_all - table_lda)
#QDA with ALL
qda.model_all = qda (V58 ~., data=train)
qda_prediction_all = predict(qda.model_all, newdata=testdata)
#accuracy
accuracy_qda_all = sum(test$V58 == qda_prediction_all$class)/length(test$V58)
#sensivity
total_spam_qda_all = sum(test$V58 == 1)
num_spam_correct_qda_all = sum((test$V58 == 1) & (qda_prediction_all$class == 1))
sensitivity_qda_all = num_spam_correct_qda_all/total_spam_qda_all
#specificity
total_non_spam_qda_all = sum(test$V58 == 0)
num_non_spam_correct_qda_all = sum((test$V58 == 0) & (qda_prediction_all$class == 0))
specificity_qda_all = num_non_spam_correct_qda_all / total_non_spam_lda_all
table_qda_all <- data.frame("Accuracy" = accuracy_qda_all, "Sensitivity" = sensitivity_qda_all, "Specificity" = specificity_qda_all)
print(table_qda_all)
print("Difference in LDA")
print(table_qda_all - table_qda)
### C
## Logistic
logistic <- glm(V58~., data=train, family=binomial(link="logit"))
predicted_prob_all <- predict(logistic, test, type="response")
prediction_logistic_all <- ifelse(predicted_prob_all > 0.5, "1","0")
#accuracy
accuracy_logistic_all = sum(test$V58 == prediction_logistic_all)/length(test$V58)
#sensivity
total_spam_logistic_all = sum(test$V58 == 1)
num_spam_correct_logistic_all = sum((test$V58 == 1) & (prediction_logistic_all == 1))
sensitivity_logistic_all = num_spam_correct_logistic_all/total_spam_logistic_all
#specificity
total_non_spam_logistic_all = sum(test$V58 == 0)
num_non_spam_correct_logistic_all = sum((test$V58 == 0) & (prediction_logistic_all == 0))
specificity_logistic_all = num_non_spam_correct_logistic_all / total_non_spam_logistic_all
table_logistic_all <- data.frame("Accuracy" = accuracy_logistic_all, "Sensitivity" = sensitivity_logistic_all, "Specificity" = specificity_logistic_all)
print(table_logistic_all)
## SVM
svm.model_all= svm(V58 ~ ., data = train, type='C-classification',kernel='linear',scale=FALSE, cost = 1)
prediction_svm_all <- predict(svm.model_all, test)
#accuracy
accuracy_svm_all <- sum(test$V58 == prediction_svm_all) / length(test$V58)
#sensitivity
total_spam_svm_all = sum(test$V58 == 1)
num_spam_correct_svm_all = sum((test$V58 == 1) & (prediction_svm_all == 1))
sensitivity_svm_all = num_spam_correct_svm_all/total_spam_svm_all
#specificity
total_non_spam_svm_all = sum(test$V58 == 0)
num_non_spam_correct_svm_all = sum((test$V58 == 0) & (prediction_svm_all == 0))
specificity_svm_all = num_non_spam_correct_svm_all / total_non_spam_svm_all
table_svm_all <- data.frame("Accuracy" = accuracy_svm_all, "Sensitivity" = sensitivity_svm_all, "Specificity" = specificity_svm_all)
print(table_svm_all)
### D
## NON LINEAR SVM
qda_55_57_test<-test[,c(55:57)]
svm.model_poly= svm(V58 ~ V55 + V56 + V57, data = train, type='C-classification',kernel='polynomial',scale=FALSE, cost = 1)
prediction_svm_poly <- predict(svm.model_poly, test)
#accuracy
accuracy_svm_poly <- sum(test$V58 == prediction_svm_poly) / length(test$V58)
#sensitivity
total_spam_svm_poly = sum(test$V58 == 1)
num_spam_correct_svm_poly = sum((test$V58 == 1) & (prediction_svm_poly == 1))
sensitivity_svm_poly = num_spam_correct_svm_poly/total_spam_svm_poly
#specificity
total_non_spam_svm_poly = sum(test$V58 == 0)
num_non_spam_correct_svm_poly = sum((test$V58 == 0) & (prediction_svm_poly == 0))
specificity_svm_poly = num_spam_correct_svm_poly / total_non_spam_svm_poly
table_svm_poly <- data.frame("Accuracy" = accuracy_svm_poly, "Sensitivity" = sensitivity_svm_poly, "Specificity" = specificity_svm_poly)
print(table_svm_poly)
###### Difference
table_svm_poly - table_svm_all
## E
n = length(test$V1)
prediction_random = rbinom(n,1,0.5)
#accuracy
accuracy_random <- sum(test$V58 == prediction_random) / length(test$V58)
#sensitivity
total_spam_random_all = sum(test$V58 == 1)
num_spam_correct_random_all = sum((test$V58 == 1) & (prediction_random == 1))
sensitivity_random_all = num_spam_correct_random_all/total_spam_random_all
#specificity
total_non_spam_random_all = sum(test$V58 == 0)
num_non_spam_correct_random_all = sum((test$V58 == 0) & (prediction_random == 0))
specificity_random_all = num_non_spam_correct_random_all / total_non_spam_random_all
table_random <- data.frame("Accuracy" = accuracy_random, "Sensitivity" = sensitivity_random_all, "Specificity" = specificity_random_all)
print(table_random)
## F
accuracy_list <- rep(NA, 11)
sensitivity_list <- rep(NA, 11)
specificity_list <- rep(NA, 11)
for (i in seq(from=0,to=1,by=0.1)){
n = length(test$V1)
prediction_random_loop = rbinom(n,1,i)
#accuracy
accuracy_random <- sum(test$V58 == prediction_random_loop) / length(test$V58)
#sensitivity
total_spam_random_all = sum(test$V58 == 1)
num_spam_correct_random_all = sum((test$V58 == 1) & (prediction_random_loop == 1))
sensitivity_random_all = num_spam_correct_random_all/total_spam_random_all
#specificity
total_non_spam_random_all = sum(test$V58 == 0)
num_non_spam_correct_random_all = sum((test$V58 == 0) & (prediction_random_loop == 0))
specificity_random_all = num_non_spam_correct_random_all / total_non_spam_random_all
accuracy_list[(i * 10)+ 1] = accuracy_random
sensitivity_list[(i * 10) + 1] = sensitivity_random_all
specificity_list[(i * 10) + 1] = specificity_random_all
}
new_specificity = 1-specificity_list
table_value = data.frame(x=(new_specificity), y= (sensitivity_list))
ggplot(table_value, aes(x,y)) +
geom_line() + geom_point() +
geom_label(aes(x+.5,y+0.5,label=paste(round(x,digits = 2),round(y,digits = 2),sep=","))) +
ggtitle("Sensitivy vs 1-specificity") + theme(plot.title = element_text(hjust = 0.5)) + xlab("1-Specificity") + ylab("Sensitivity")
for (i in seq(0,11)) {
print(sensitivity_list[i] + specificity_list[i])
}
sensitivity_list + specificity_list
length(train)
## G
nodevalues <- trainControl(method="cv", number=5)
rf.fit = randomForest(as.factor(V58)~.,data=train, ntree = 500, mtry = 7,importance=TRUE, trControl = nodevalues)
prediction_rf <- predict(rf.fit, test)
#accuracy
accuracy_rf <- sum(test$V58 == prediction_rf) / length(test$V58)
#sensitivity
total_spam_rf_all = sum(test$V58 == 1)
num_spam_correct_rf_all = sum((test$V58 == 1) & (prediction_rf == 1))
sensitivity_rf_all = num_spam_correct_rf_all/total_spam_rf_all
#specificity
total_non_spam_rf_all = sum(test$V58 == 0)
num_non_spam_correct_rf_all = sum((test$V58 == 0) & (prediction_rf == 0))
specificity_rf_all = num_non_spam_correct_rf_all / total_non_spam_rf_all
table_rf <- data.frame("Accuracy" = accuracy_rf, "Sensitivity" = sensitivity_rf_all, "Specificity" = specificity_rf_all)
print(table_rf)
## H
help(importance)
par(mar=rep(2,4))
barplot(importance(rf.fit)[,4])
title(main=paste('Mean Decrease Gini values'))
## I
grid <-expand.grid(n.trees = c(100,200,500,1000,2000),
shrinkage = seq(0.01,0.1,0.01),
interaction.depth = 1,
n.minobsinnode = 10
)
gbm.fit <- train(as.factor(V58) ~ .,
data = train,
distribution="adaboost",
method = "gbm",
trControl = nodevalues,
tuneGrid = grid,
verbose=FALSE)
prediction_gbm = predict(gbm.fit, test)
#accuracy
accuracy_gbm  <- sum(test$V58 == prediction_gbm ) / length(test$V58)
#sensitivity
total_spam_gbm_all = sum(test$V58 == 1)
num_spam_correct_gbm_all = sum((test$V58 == 1) & (prediction_gbm  == 1))
sensitivity_gbm_all = num_spam_correct_gbm_all/total_spam_gbm_all
#specificity
total_non_spam_gbm_all = sum(test$V58 == 0)
num_non_spam_correct_gbm_all = sum((test$V58 == 0) & (prediction_gbm  == 0))
specificity_gbm_all = num_non_spam_correct_gbm_all / total_non_spam_gbm_all
table_gbm <- data.frame("Accuracy" = accuracy_gbm, "Sensitivity" = sensitivity_gbm_all, "Specificity" = specificity_gbm_all)
print(table_gbm)
library(e1071)
library(ElemStatLearn)
library(kernlab)
library(gbm)
library(MASS)
library(glmnet)
library(kknn)
library(class)
library(deldir)
library(lars)
library(PerformanceAnalytics)
library(leaps)
library(ncvreg)
library(party)
library(rpart)
library(tree)
library(ipred)
library(rpart)
library(randomForest)
library(ggplot2)
library(caret)
library(e1071)
library(ElemStatLearn)
library(kernlab)
library(gbm)
library(MASS)
library(glmnet)
library(kknn)
library(class)
library(deldir)
library(lars)
library(PerformanceAnalytics)
library(leaps)
library(ncvreg)
library(party)
library(rpart)
library(tree)
library(ipred)
library(rpart)
library(randomForest)
library(ggplot2)
library(caret)
set.seed(1)
setwd("/Users/maxryoo/Documents/Fall 2019/STAT 5630/Code/hw3")
train = read.table("traindata.txt")
test = read.table("testdata.txt")
head(train)
traindata=train[,-58]
testdata=test[,-58]
## A
spamratio <- sum(train$V58==1)/length(train$V58)
# spam ration = 0.3973899
nospamration<- sum(train$V58==0)/length(train$V58)
# not spam ration = 0.6026101
print(c("Spam entry Proportion: ", spamratio))
print(c("Not Spam entry Proportion: ", nospamration))
## A
spamratio_test <- sum(test$V58==1)/length(test$V58)
# spam ration = 0.3973899
nospamration_test <- sum(test$V58==0)/length(test$V58)
# not spam ration = 0.6026101
print(c("Spam entry Proportion: ", spamratio_test))
print(c("Not Spam entry Proportion: ", nospamration_test))
#LDA with V55-57
lda_55_57_test<-test[,c(55:57)]
lda.model = lda (V58 ~ V55 + V56 + V57, data=train)
lda_prediction = predict(lda.model, newdata=lda_55_57_test)
#accuracy
accuracy_lda = sum(test$V58 == lda_prediction$class)/length(test$V58)
#sensivity
total_spam_lda = sum(test$V58 == 1)
num_spam_correct_lda = sum((test$V58 == 1) & (lda_prediction$class == 1))
sensitivity_lda = num_spam_correct_lda/total_spam_lda
#specificity
total_non_spam_lda = sum(test$V58 == 0)
num_non_spam_correct_lda = sum((test$V58 == 0) & (lda_prediction$class == 0))
specificity_lda = num_non_spam_correct_lda / total_non_spam_lda
table_lda <- data.frame("Accuracy" = accuracy_lda, "Sensitivity" = sensitivity_lda, "Specificity" = specificity_lda)
print(table_lda)
#QDA with V55-57
qda_55_57_test<-test[,c(55:57)]
qda.model = qda (V58 ~ V55 + V56 + V57, data=train)
qda_prediction = predict(qda.model, newdata=qda_55_57_test)
#accuracy
accuracy_qda = sum(test$V58 == qda_prediction$class)/length(test$V58)
#sensivity
total_spam_qda = sum(test$V58 == 1)
num_spam_correct_qda = sum((test$V58 == 1) & (qda_prediction$class == 1))
sensitivity_qda = num_spam_correct_qda/total_spam_qda
#specificity
total_non_spam_qda = sum(test$V58 == 0)
num_non_spam_correct_qda = sum((test$V58 == 0) & (qda_prediction$class == 0))
specificity_qda = num_non_spam_correct_qda / total_non_spam_qda
table_qda <- data.frame("Accuracy" = accuracy_qda, "Sensitivity" = sensitivity_qda, "Specificity" = specificity_qda)
print(table_qda)
#LDA with ALL
lda.model_all = lda (V58 ~., data=train)
lda_prediction_all = predict(lda.model_all, newdata=testdata)
#accuracy
accuracy_lda_all = sum(test$V58 == lda_prediction_all$class)/length(test$V58)
#sensivity
total_spam_lda_all = sum(test$V58 == 1)
num_spam_correct_lda_all = sum((test$V58 == 1) & (lda_prediction_all$class == 1))
sensitivity_lda_all = num_spam_correct_lda_all/total_spam_lda_all
#specificity
total_non_spam_lda_all = sum(test$V58 == 0)
num_non_spam_correct_lda_all = sum((test$V58 == 0) & (lda_prediction_all$class == 0))
specificity_lda_all = num_non_spam_correct_lda_all / total_non_spam_lda_all
table_lda_all <- data.frame("Accuracy" = accuracy_lda_all, "Sensitivity" = sensitivity_lda_all, "Specificity" = specificity_lda_all)
print(table_lda_all)
print("Difference in LDA")
print(table_lda_all - table_lda)
#QDA with ALL
qda.model_all = qda (V58 ~., data=train)
qda_prediction_all = predict(qda.model_all, newdata=testdata)
#accuracy
accuracy_qda_all = sum(test$V58 == qda_prediction_all$class)/length(test$V58)
#sensivity
total_spam_qda_all = sum(test$V58 == 1)
num_spam_correct_qda_all = sum((test$V58 == 1) & (qda_prediction_all$class == 1))
sensitivity_qda_all = num_spam_correct_qda_all/total_spam_qda_all
#specificity
total_non_spam_qda_all = sum(test$V58 == 0)
num_non_spam_correct_qda_all = sum((test$V58 == 0) & (qda_prediction_all$class == 0))
specificity_qda_all = num_non_spam_correct_qda_all / total_non_spam_lda_all
table_qda_all <- data.frame("Accuracy" = accuracy_qda_all, "Sensitivity" = sensitivity_qda_all, "Specificity" = specificity_qda_all)
print(table_qda_all)
print("Difference in LDA")
print(table_qda_all - table_qda)
logistic <- glm(V58~., data=train, family=binomial(link="logit"))
predicted_prob_all <- predict(logistic, test, type="response")
prediction_logistic_all <- ifelse(predicted_prob_all > 0.5, "1","0")
#accuracy
accuracy_logistic_all = sum(test$V58 == prediction_logistic_all)/length(test$V58)
#sensivity
total_spam_logistic_all = sum(test$V58 == 1)
num_spam_correct_logistic_all = sum((test$V58 == 1) & (prediction_logistic_all == 1))
sensitivity_logistic_all = num_spam_correct_logistic_all/total_spam_logistic_all
#specificity
total_non_spam_logistic_all = sum(test$V58 == 0)
num_non_spam_correct_logistic_all = sum((test$V58 == 0) & (prediction_logistic_all == 0))
specificity_logistic_all = num_non_spam_correct_logistic_all / total_non_spam_logistic_all
table_logistic_all <- data.frame("Accuracy" = accuracy_logistic_all, "Sensitivity" = sensitivity_logistic_all, "Specificity" = specificity_logistic_all)
print(table_logistic_all)
svm.model_all= svm(V58 ~ ., data = train, type='C-classification',kernel='linear',scale=FALSE, cost = 1)
prediction_svm_all <- predict(svm.model_all, test)
#accuracy
accuracy_svm_all <- sum(test$V58 == prediction_svm_all) / length(test$V58)
#sensitivity
total_spam_svm_all = sum(test$V58 == 1)
num_spam_correct_svm_all = sum((test$V58 == 1) & (prediction_svm_all == 1))
sensitivity_svm_all = num_spam_correct_svm_all/total_spam_svm_all
#specificity
total_non_spam_svm_all = sum(test$V58 == 0)
num_non_spam_correct_svm_all = sum((test$V58 == 0) & (prediction_svm_all == 0))
specificity_svm_all = num_non_spam_correct_svm_all / total_non_spam_svm_all
table_svm_all <- data.frame("Accuracy" = accuracy_svm_all, "Sensitivity" = sensitivity_svm_all, "Specificity" = specificity_svm_all)
print(table_svm_all)
qda_55_57_test<-test[,c(55:57)]
svm.model_poly= svm(V58 ~ V55 + V56 + V57, data = train, type='C-classification',kernel='polynomial',scale=FALSE, cost = 1)
prediction_svm_poly <- predict(svm.model_poly, test)
#accuracy
accuracy_svm_poly <- sum(test$V58 == prediction_svm_poly) / length(test$V58)
#sensitivity
total_spam_svm_poly = sum(test$V58 == 1)
num_spam_correct_svm_poly = sum((test$V58 == 1) & (prediction_svm_poly == 1))
sensitivity_svm_poly = num_spam_correct_svm_poly/total_spam_svm_poly
#specificity
total_non_spam_svm_poly = sum(test$V58 == 0)
num_non_spam_correct_svm_poly = sum((test$V58 == 0) & (prediction_svm_poly == 0))
specificity_svm_poly = num_spam_correct_svm_poly / total_non_spam_svm_poly
table_svm_poly <- data.frame("Accuracy" = accuracy_svm_poly, "Sensitivity" = sensitivity_svm_poly, "Specificity" = specificity_svm_poly)
print(table_svm_poly)
n = length(test$V1)
prediction_random = rbinom(n,1,0.5)
#accuracy
accuracy_random <- sum(test$V58 == prediction_random) / length(test$V58)
#sensitivity
total_spam_random_all = sum(test$V58 == 1)
num_spam_correct_random_all = sum((test$V58 == 1) & (prediction_random == 1))
sensitivity_random_all = num_spam_correct_random_all/total_spam_random_all
#specificity
total_non_spam_random_all = sum(test$V58 == 0)
num_non_spam_correct_random_all = sum((test$V58 == 0) & (prediction_random == 0))
specificity_random_all = num_non_spam_correct_random_all / total_non_spam_random_all
table_random <- data.frame("Accuracy" = accuracy_random, "Sensitivity" = sensitivity_random_all, "Specificity" = specificity_random_all)
print(table_random)
accuracy_list <- rep(NA, 11)
sensitivity_list <- rep(NA, 11)
specificity_list <- rep(NA, 11)
for (i in seq(from=0,to=1,by=0.1)){
n = length(test$V1)
prediction_random_loop = rbinom(n,1,i)
#accuracy
accuracy_random <- sum(test$V58 == prediction_random_loop) / length(test$V58)
#sensitivity
total_spam_random_all = sum(test$V58 == 1)
num_spam_correct_random_all = sum((test$V58 == 1) & (prediction_random_loop == 1))
sensitivity_random_all = num_spam_correct_random_all/total_spam_random_all
#specificity
total_non_spam_random_all = sum(test$V58 == 0)
num_non_spam_correct_random_all = sum((test$V58 == 0) & (prediction_random_loop == 0))
specificity_random_all = num_non_spam_correct_random_all / total_non_spam_random_all
accuracy_list[(i * 10)+ 1] = accuracy_random
sensitivity_list[(i * 10) + 1] = sensitivity_random_all
specificity_list[(i * 10) + 1] = specificity_random_all
}
new_specificity = 1-specificity_list
table_value = data.frame(x=(new_specificity), y= (sensitivity_list))
ggplot(table_value, aes(x,y)) +
geom_line() + geom_point() +
geom_label(aes(x+.5,y+0.5,label=paste(round(x,digits = 2),round(y,digits = 2),sep=","))) +
ggtitle("Sensitivy vs 1-specificity") + theme(plot.title = element_text(hjust = 0.5)) + xlab("1-Specificity") + ylab("Sensitivity")
for (i in seq(0,11)) {
print(sensitivity_list[i])
print(1 - specificity_list[i])
print(sensitivity_list[i] + specificity_list[i])
}
sensitivity_list + specificity_list
max(sensitivity_list + specificity_list)
nodevalues <- trainControl(method="cv", number=5)
rf.fit = randomForest(as.factor(V58)~.,data=train, ntree = 500, mtry = 7,importance=TRUE, trControl = nodevalues)
prediction_rf <- predict(rf.fit, test)
#accuracy
accuracy_rf <- sum(test$V58 == prediction_rf) / length(test$V58)
#sensitivity
total_spam_rf_all = sum(test$V58 == 1)
num_spam_correct_rf_all = sum((test$V58 == 1) & (prediction_rf == 1))
sensitivity_rf_all = num_spam_correct_rf_all/total_spam_rf_all
#specificity
total_non_spam_rf_all = sum(test$V58 == 0)
num_non_spam_correct_rf_all = sum((test$V58 == 0) & (prediction_rf == 0))
specificity_rf_all = num_non_spam_correct_rf_all / total_non_spam_rf_all
table_rf <- data.frame("Accuracy" = accuracy_rf, "Sensitivity" = sensitivity_rf_all, "Specificity" = specificity_rf_all)
print(table_rf)
## H
help(importance)
par(mar=rep(2,4))
barplot(importance(rf.fit)[,4])
title(main=paste('Mean Decrease Gini values'))
## I
grid <-expand.grid(n.trees = c(100,200,500,1000,2000),
shrinkage = seq(0.01,0.1,0.01),
interaction.depth = 1,
n.minobsinnode = 10
)
gbm.fit <- train(as.factor(V58) ~ .,
data = train,
distribution="adaboost",
method = "gbm",
trControl = nodevalues,
tuneGrid = grid,
verbose=FALSE)
prediction_gbm = predict(gbm.fit, test)
#accuracy
accuracy_gbm  <- sum(test$V58 == prediction_gbm ) / length(test$V58)
#sensitivity
total_spam_gbm_all = sum(test$V58 == 1)
num_spam_correct_gbm_all = sum((test$V58 == 1) & (prediction_gbm  == 1))
sensitivity_gbm_all = num_spam_correct_gbm_all/total_spam_gbm_all
#specificity
total_non_spam_gbm_all = sum(test$V58 == 0)
num_non_spam_correct_gbm_all = sum((test$V58 == 0) & (prediction_gbm  == 0))
specificity_gbm_all = num_non_spam_correct_gbm_all / total_non_spam_gbm_all
table_gbm <- data.frame("Accuracy" = accuracy_gbm, "Sensitivity" = sensitivity_gbm_all, "Specificity" = specificity_gbm_all)
print(table_gbm)
