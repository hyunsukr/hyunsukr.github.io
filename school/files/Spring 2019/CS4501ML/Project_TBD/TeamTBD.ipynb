{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TeamTBD.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "hvTxXFdgc2_r",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        " # Import some common packages\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from google.colab import files\n",
        "import io"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AndBgVlNfeYW",
        "colab_type": "code",
        "outputId": "b3fd3fe8-6446-4d65-f8ce-20ebf53824e0",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": "OK"
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "cell_type": "code",
      "source": [
        "#Upload teh data hour.csv\n",
        "uploaded_Hour = files.upload()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-60d472a4-6944-44a8-acbe-bb97b436edc5\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-60d472a4-6944-44a8-acbe-bb97b436edc5\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving hour.csv to hour.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "hdcEAR8mdZh2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "bike = pd.read_csv(io.StringIO(uploaded_Hour[\"hour.csv\"].decode(\"utf-8\")))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ImxsvfPaffiW",
        "colab_type": "code",
        "outputId": "f5049249-c35e-4aa9-ab1e-fd22690a949f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "cell_type": "code",
      "source": [
        "#First couple of entries\n",
        "bike.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>instant</th>\n",
              "      <th>dteday</th>\n",
              "      <th>season</th>\n",
              "      <th>yr</th>\n",
              "      <th>mnth</th>\n",
              "      <th>hr</th>\n",
              "      <th>holiday</th>\n",
              "      <th>weekday</th>\n",
              "      <th>workingday</th>\n",
              "      <th>weathersit</th>\n",
              "      <th>temp</th>\n",
              "      <th>atemp</th>\n",
              "      <th>hum</th>\n",
              "      <th>windspeed</th>\n",
              "      <th>casual</th>\n",
              "      <th>registered</th>\n",
              "      <th>cnt</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>2011-01-01</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.24</td>\n",
              "      <td>0.2879</td>\n",
              "      <td>0.81</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3</td>\n",
              "      <td>13</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>2011-01-01</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.22</td>\n",
              "      <td>0.2727</td>\n",
              "      <td>0.80</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8</td>\n",
              "      <td>32</td>\n",
              "      <td>40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>2011-01-01</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.22</td>\n",
              "      <td>0.2727</td>\n",
              "      <td>0.80</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5</td>\n",
              "      <td>27</td>\n",
              "      <td>32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>2011-01-01</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.24</td>\n",
              "      <td>0.2879</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3</td>\n",
              "      <td>10</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>2011-01-01</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.24</td>\n",
              "      <td>0.2879</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   instant      dteday  season  yr  mnth  hr  holiday  weekday  workingday  \\\n",
              "0        1  2011-01-01       1   0     1   0        0        6           0   \n",
              "1        2  2011-01-01       1   0     1   1        0        6           0   \n",
              "2        3  2011-01-01       1   0     1   2        0        6           0   \n",
              "3        4  2011-01-01       1   0     1   3        0        6           0   \n",
              "4        5  2011-01-01       1   0     1   4        0        6           0   \n",
              "\n",
              "   weathersit  temp   atemp   hum  windspeed  casual  registered  cnt  \n",
              "0           1  0.24  0.2879  0.81        0.0       3          13   16  \n",
              "1           1  0.22  0.2727  0.80        0.0       8          32   40  \n",
              "2           1  0.22  0.2727  0.80        0.0       5          27   32  \n",
              "3           1  0.24  0.2879  0.75        0.0       3          10   13  \n",
              "4           1  0.24  0.2879  0.75        0.0       0           1    1  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "metadata": {
        "id": "QioMpuzhaLxU",
        "colab_type": "code",
        "outputId": "37122bea-0597-44f2-de74-cd6d59585ccb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        }
      },
      "cell_type": "code",
      "source": [
        "#explore the response variables\n",
        "bike['cnt'].value_counts()[0:10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5     260\n",
              "6     236\n",
              "4     231\n",
              "3     224\n",
              "2     208\n",
              "7     198\n",
              "8     182\n",
              "1     158\n",
              "10    155\n",
              "11    147\n",
              "Name: cnt, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "metadata": {
        "id": "T24jRvqok5f2",
        "colab_type": "code",
        "outputId": "e93e2181-22e1-420b-86fe-6c2d3d60751a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "cell_type": "code",
      "source": [
        "#Percentiles\n",
        "print(\"Mean: \", np.mean(bike[\"cnt\"]))\n",
        "print(\"Std: \", np.std(bike[\"cnt\"]))\n",
        "print(\"25%: \", np.percentile(bike[\"cnt\"], 25))\n",
        "print(\"75%: \", np.percentile(bike[\"cnt\"], 75))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean:  189.46308763450142\n",
            "Std:  181.38238043116962\n",
            "25%:  40.0\n",
            "75%:  281.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "xwVQYfEBlvI9",
        "colab_type": "code",
        "outputId": "acf616c4-d494-4d2c-a8c8-d99b8d213a40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        }
      },
      "cell_type": "code",
      "source": [
        "##################################\n",
        "# DATA CLEANING & FEATURE SCALING#\n",
        "# ################################\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import Imputer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "try:\n",
        "  from sklearn.impute import SimpleImputer # Scikit-Learn 0.20+\n",
        "except ImportError:\n",
        "  from sklearn.preprocessing import Imputer as SimpleImputer\n",
        "try:\n",
        "    from sklearn.compose import ColumnTransformer\n",
        "except ImportError:\n",
        "    from future_encoders import ColumnTransformer # Scikit-Learn < 0.20\n",
        "X_labels = ['season','mnth','hr', 'holiday', 'weekday', 'workingday', 'weathersit', 'temp', 'atemp', 'hum', 'windspeed']\n",
        "X = bike[X_labels]\n",
        "Y = bike[[\"cnt\"]]\n",
        "X_train_pre, X_test_pre, Y_train, Y_test = train_test_split(X,Y, random_state=1, test_size=0.2) # 80-20 Train-Test split\n",
        "\n",
        "# Permission granted to use std_scaler \n",
        "num_pipeline = Pipeline([\n",
        "    ('imputer', SimpleImputer(strategy=\"median\")),\n",
        "    ('std_scaler', StandardScaler()),\n",
        "])\n",
        "\n",
        "x_num = ['hr', 'holiday', 'weekday', 'workingday', 'weathersit', 'temp', 'atemp', 'hum', 'windspeed']\n",
        "cat_attribs = [\"season\",\"mnth\"]\n",
        "#Make a full pipeline with num and onehot encoder\n",
        "full_pipeline = ColumnTransformer([\n",
        "    (\"num\", num_pipeline, x_num),\n",
        "    (\"cat\", OneHotEncoder(sparse=False), cat_attribs),\n",
        "])\n",
        "X_train = full_pipeline.fit_transform(X_train_pre)\n",
        "X_test = full_pipeline.fit_transform(X_test_pre)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
            "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
            "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
            "  warnings.warn(msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
            "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
            "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "zj8L2sqeqn3y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Classify the response variable into three classes 0, 1, 2\n",
        "Y_train_class = []\n",
        "Y_test_class = []\n",
        "low = np.percentile(Y_train[\"cnt\"], 25)\n",
        "high = np.percentile(Y_train[\"cnt\"], 75)\n",
        "\n",
        "\n",
        "# Only supposed to use Training according to TA\n",
        "for element in Y_train[\"cnt\"]:\n",
        "  if element <= low:\n",
        "    Y_train_class.append(0)\n",
        "  elif low < element <= high:\n",
        "    Y_train_class.append(1)\n",
        "  else:\n",
        "    Y_train_class.append(2)\n",
        "    \n",
        "for element in Y_test[\"cnt\"]:\n",
        "  if element <= low:\n",
        "    Y_test_class.append(0)\n",
        "  elif low < element <= high:\n",
        "    Y_test_class.append(1)\n",
        "  else:\n",
        "    Y_test_class.append(2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SzM4eYAzsCLM",
        "colab_type": "code",
        "outputId": "c5bcf0a8-baa0-4730-d4d1-f58f1218f012",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "#classes of response variable\n",
        "print(Y_train_class[0:5])\n",
        "print(Y_test_class[0:5])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1, 0, 0, 2, 2]\n",
            "[2, 1, 1, 1, 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "JsdEN5MnuA56",
        "colab_type": "code",
        "outputId": "f020971a-8b95-4730-d828-5566dbfa84c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "cell_type": "code",
      "source": [
        "print(\"X_train Dimension: \", len(X_train))\n",
        "print(\"Y_train Dimension: \", len(Y_train_class))\n",
        "print(\"X_test Dimension: \", len(X_test))\n",
        "print(\"Y_test Dimension: \", len(Y_test_class))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train Dimension:  13903\n",
            "Y_train Dimension:  13903\n",
            "X_test Dimension:  3476\n",
            "Y_test Dimension:  3476\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "hxWIf3FDsxUt",
        "colab_type": "code",
        "outputId": "8d2f9d49-2408-4d9c-a527-27543326d569",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "# Training your svm here\n",
        "soft_clf = LogisticRegression(random_state=42, solver=\"lbfgs\",multi_class = \"multinomial\")\n",
        "soft_clf.fit(X_train,Y_train_class)\n",
        "# Testing your svm here\n",
        "from sklearn.metrics import precision_score, recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "prediction = soft_clf.predict(X_test)\n",
        "print(\"Accuracy: \", accuracy_score(Y_test_class, prediction))\n",
        "print(\"Precision: \",precision_score(Y_test_class, prediction,average=None))\n",
        "print(\"Recall: \", recall_score(Y_test_class, prediction, average=None))\n",
        "print(\"F-1: \", f1_score(Y_test_class, prediction, average=None))\n",
        "mse = mean_squared_error(Y_test_class, prediction)\n",
        "rmse = np.sqrt(mse)\n",
        "print(\"MSE: \", mse)\n",
        "print(\"RMSE: \", rmse)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy:  0.6682968929804373\n",
            "Precision:  [0.71897436 0.64782836 0.65084746]\n",
            "Recall:  [0.78149387 0.73124631 0.43340858]\n",
            "F-1:  [0.74893162 0.68701443 0.5203252 ]\n",
            "MSE:  0.3532796317606444\n",
            "RMSE:  0.5943733101011892\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "o4Qj7yFWt8-c",
        "colab_type": "code",
        "outputId": "dca322d7-d102-43df-c3e1-8ff2c12b9134",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        }
      },
      "cell_type": "code",
      "source": [
        "##Fine Tune\n",
        "##Explore different Cs\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "soft_clf20 = LogisticRegression(C=20, random_state=42, solver=\"lbfgs\",multi_class = \"multinomial\")\n",
        "soft_clf20.fit(X_train, Y_train_class)\n",
        "prediction = soft_clf20.predict(X_test)\n",
        "print(\"C=20\")\n",
        "print(\"Accuracy: \", accuracy_score(Y_test_class, prediction))\n",
        "print(\"Precision: \",precision_score(Y_test_class, prediction,average=None))\n",
        "print(\"Recall: \", recall_score(Y_test_class, prediction, average=None))\n",
        "print(\"F-1: \", f1_score(Y_test_class, prediction, average=None))\n",
        "mse = mean_squared_error(Y_test_class, prediction)\n",
        "rmse = np.sqrt(mse)\n",
        "print(\"MSE: \", mse)\n",
        "print(\"RMSE: \", rmse)\n",
        "\n",
        "soft_clf5 = LogisticRegression(C=5, random_state=42, solver=\"lbfgs\",multi_class = \"multinomial\")\n",
        "soft_clf5.fit(X_train, Y_train_class)\n",
        "prediction = soft_clf5.predict(X_test)\n",
        "print(\"C=5\")\n",
        "print(\"Accuracy: \", accuracy_score(Y_test_class, prediction))\n",
        "print(\"Precision: \",precision_score(Y_test_class, prediction,average=None))\n",
        "print(\"Recall: \", recall_score(Y_test_class, prediction, average=None))\n",
        "print(\"F-1: \", f1_score(Y_test_class, prediction, average=None))\n",
        "\n",
        "soft_clf1_5 = LogisticRegression(C=1.5, random_state=42, solver=\"lbfgs\",multi_class = \"multinomial\")\n",
        "soft_clf1_5.fit(X_train, Y_train_class)\n",
        "prediction = soft_clf1_5.predict(X_test)\n",
        "print(\"C=1.5\")\n",
        "print(\"Accuracy: \", accuracy_score(Y_test_class, prediction))\n",
        "print(\"Precision: \",precision_score(Y_test_class, prediction,average=None))\n",
        "print(\"Recall: \", recall_score(Y_test_class, prediction, average=None))\n",
        "print(\"F-1: \", f1_score(Y_test_class, prediction, average=None))\n",
        "\n",
        "soft_clf1 = LogisticRegression(C=1, random_state=42, solver=\"lbfgs\",multi_class = \"multinomial\")\n",
        "soft_clf1.fit(X_train, Y_train_class)\n",
        "prediction = soft_clf1.predict(X_test)\n",
        "print(\"C=1\")\n",
        "print(\"Accuracy: \", accuracy_score(Y_test_class, prediction))\n",
        "print(\"Precision: \",precision_score(Y_test_class, prediction,average=None))\n",
        "print(\"Recall: \", recall_score(Y_test_class, prediction, average=None))\n",
        "print(\"F-1: \", f1_score(Y_test_class, prediction, average=None))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "C=20\n",
            "Accuracy:  0.6694476409666283\n",
            "Precision:  [0.71836735 0.64971159 0.65195246]\n",
            "Recall:  [0.78483835 0.73183698 0.43340858]\n",
            "F-1:  [0.75013319 0.68833333 0.52067797]\n",
            "MSE:  0.3538550057537399\n",
            "RMSE:  0.5948571305395438\n",
            "C=5\n",
            "Accuracy:  0.6694476409666283\n",
            "Precision:  [0.71836735 0.64971159 0.65195246]\n",
            "Recall:  [0.78483835 0.73183698 0.43340858]\n",
            "F-1:  [0.75013319 0.68833333 0.52067797]\n",
            "C=1.5\n",
            "Accuracy:  0.6685845799769851\n",
            "Precision:  [0.71807967 0.6486911  0.65076661]\n",
            "Recall:  [0.78372352 0.73183698 0.43115124]\n",
            "F-1:  [0.74946695 0.6877602  0.51866938]\n",
            "C=1\n",
            "Accuracy:  0.6682968929804373\n",
            "Precision:  [0.71897436 0.64782836 0.65084746]\n",
            "Recall:  [0.78149387 0.73124631 0.43340858]\n",
            "F-1:  [0.74893162 0.68701443 0.5203252 ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "tux91yV4wdlk",
        "colab_type": "code",
        "outputId": "4fd907f9-02c1-412b-da06-092bd2504591",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 451
        }
      },
      "cell_type": "code",
      "source": [
        "#Grid Search for our svm model\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from scipy.stats import uniform\n",
        "soft_clf = LogisticRegression(random_state=42, solver=\"lbfgs\",multi_class = \"multinomial\")\n",
        "param_distributions = {\"C\": np.arange(0, 10, 0.1)}\n",
        "grid_search = GridSearchCV(soft_clf, param_distributions, cv=5, verbose=3, n_jobs=-1)\n",
        "grid_search.fit(X_train, Y_train_class)\n",
        "clf_regress = grid_search\n",
        "print(\"best estimator: \", grid_search.best_params_)\n",
        "print(\"best score: \", grid_search.best_score_)\n",
        "grid_search.best_estimator_.fit(X_train, Y_train_class)\n",
        "predictionb = grid_search.best_estimator_.predict(X_test)\n",
        "print(\"C=Grid Search\")\n",
        "print(\"Accuracy: \", accuracy_score(Y_test_class, predictionb))\n",
        "print(\"Precision: \",precision_score(Y_test_class, predictionb,average=None))\n",
        "print(\"Recall: \", recall_score(Y_test_class, predictionb, average=None))\n",
        "print(\"F-1: \", f1_score(Y_test_class, predictionb, average=None))\n",
        "\n",
        "# Testing your svm here\n",
        "from sklearn.metrics import precision_score, recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import mean_squared_error\n",
        "print(\"\")\n",
        "print(\"C=1=default\")\n",
        "soft_clf = LogisticRegression(random_state=42, solver=\"lbfgs\",multi_class = \"multinomial\")\n",
        "soft_clf.fit(X_train,Y_train_class)\n",
        "prediction = soft_clf.predict(X_test)\n",
        "print(\"Accuracy: \", accuracy_score(Y_test_class, prediction))\n",
        "print(\"Precision: \",precision_score(Y_test_class, prediction,average=None))\n",
        "print(\"Recall: \", recall_score(Y_test_class, prediction, average=None))\n",
        "print(\"F-1: \", f1_score(Y_test_class, prediction, average=None))\n",
        "print(\"\")\n",
        "print(\"Difference between default and fine tuning\")\n",
        "print(\"Accuracy_difference: \", accuracy_score(Y_test_class, predictionb) - accuracy_score(Y_test_class, prediction))\n",
        "print(\"Precision_difference: \",precision_score(Y_test_class, predictionb,average=None) - precision_score(Y_test_class, prediction,average=None))\n",
        "print(\"Recall_difference: \", recall_score(Y_test_class, predictionb, average=None) - recall_score(Y_test_class, prediction, average=None))\n",
        "print(\"F-1_difference: \", f1_score(Y_test_class, predictionb, average=None) - f1_score(Y_test_class, prediction, average=None))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:   21.0s\n",
            "[Parallel(n_jobs=-1)]: Done 124 tasks      | elapsed:  1.6min\n",
            "[Parallel(n_jobs=-1)]: Done 284 tasks      | elapsed:  3.6min\n",
            "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:  6.1min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "best estimator:  {'C': 0.2}\n",
            "best score:  0.6681291807523556\n",
            "C=Grid Search\n",
            "Accuracy:  0.6682968929804373\n",
            "Precision:  [0.71954964 0.64733542 0.65128205]\n",
            "Recall:  [0.78372352 0.73183698 0.43002257]\n",
            "F-1:  [0.75026681 0.6869975  0.51801496]\n",
            "\n",
            "C=1=default\n",
            "Accuracy:  0.6682968929804373\n",
            "Precision:  [0.71897436 0.64782836 0.65084746]\n",
            "Recall:  [0.78149387 0.73124631 0.43340858]\n",
            "F-1:  [0.74893162 0.68701443 0.5203252 ]\n",
            "\n",
            "Difference between default and fine tuning\n",
            "Accuracy_difference:  0.0\n",
            "Precision_difference:  [ 0.00057528 -0.00049294  0.00043459]\n",
            "Recall_difference:  [ 0.00222965  0.00059067 -0.003386  ]\n",
            "F-1_difference:  [ 1.33518503e-03 -1.69235612e-05 -2.31024744e-03]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "BQ3BJZwlcxV_",
        "colab_type": "code",
        "outputId": "d71c2edc-6510-4039-c722-bbb0e2281b31",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn import tree\n",
        "clf = tree.DecisionTreeClassifier()\n",
        "clf = clf.fit(X_train, Y_train_class)\n",
        "output = clf.predict(X_test)\n",
        "print(\"Decision class 3\")\n",
        "print(\"Accurarcy: \", accuracy_score(Y_test_class,output))\n",
        "print(\"Precision: \", precision_score(Y_test_class,output, average=None))\n",
        "print(\"Recall: \", recall_score(Y_test_class,output, average=None))\n",
        "print(\"f1: \", f1_score(Y_test_class,output, average=None))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Decision class 3\n",
            "Accurarcy:  0.8331415420023015\n",
            "Precision:  [0.9003517  0.82122261 0.79190101]\n",
            "Recall:  [0.85618729 0.84111045 0.79458239]\n",
            "f1:  [0.87771429 0.83104756 0.79323944]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Z4RZwcN6juTy",
        "colab_type": "code",
        "outputId": "49aa424a-d099-4828-e157-1584eeed2165",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        }
      },
      "cell_type": "code",
      "source": [
        "#Fine tune Decision tree\n",
        "##Original\n",
        "clf = tree.DecisionTreeClassifier()\n",
        "clf = clf.fit(X_train, Y_train_class)\n",
        "output = clf.predict(X_test)\n",
        "print(\"Decision class 3\")\n",
        "accprev = accuracy_score(Y_test_class,output)\n",
        "precprev = precision_score(Y_test_class,output, average=None)\n",
        "recallprev = recall_score(Y_test_class,output, average=None)\n",
        "f1prev = f1_score(Y_test_class,output, average=None)\n",
        "print(\"Accurarcy: \", accuracy_score(Y_test_class,output))\n",
        "print(\"Precision: \", precision_score(Y_test_class,output, average=None))\n",
        "print(\"Recall: \", recall_score(Y_test_class,output, average=None))\n",
        "print(\"f1: \", f1_score(Y_test_class,output, average=None))\n",
        "\n",
        "##Fine tune\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "max_depths = np.linspace(1, 64, 64, endpoint=True)\n",
        "\n",
        "best_accuracy = None\n",
        "best_depth = None\n",
        "best_prec = None\n",
        "best_rec = None\n",
        "best_f1 = None\n",
        "clf_df = None\n",
        "for max_depth in max_depths:\n",
        "  dt = DecisionTreeClassifier(max_depth=max_depth)\n",
        "  dt.fit(X_train, Y_train_class)\n",
        "  train_pred = dt.predict(X_train)  \n",
        "  output = dt.predict(X_test)\n",
        "  \n",
        "  \n",
        "  if best_accuracy == None:\n",
        "    best_accuracy = accuracy_score(Y_test_class,output)\n",
        "    best_depth = max_depth\n",
        "    best_prec = precision_score(Y_test_class,output, average=None)\n",
        "    best_rec = recall_score(Y_test_class,output, average=None)\n",
        "    best_f1 = f1_score(Y_test_class,output, average=None)\n",
        "  if accuracy_score(Y_test_class,output) > best_accuracy:\n",
        "    best_accuracy = accuracy_score(Y_test_class,output)\n",
        "    best_depth = max_depth\n",
        "    best_prec = precision_score(Y_test_class,output, average=None)\n",
        "    best_rec = recall_score(Y_test_class,output, average=None)\n",
        "    best_f1 = f1_score(Y_test_class,output, average=None)\n",
        "    clf_df = dt\n",
        "print(\"3 classes\")\n",
        "print(\"Accuracy: \", best_accuracy)\n",
        "print(\"Depth: \", best_depth)\n",
        "print(\"Precision: \", best_prec)\n",
        "print(\"Recall: \", best_rec)\n",
        "print(\"F-1: \", best_f1)\n",
        "print(\"\")\n",
        "print(\"The difference\")\n",
        "print(\"Accuracy: \", best_accuracy - accprev)\n",
        "print(\"Precision: \", best_prec - precprev)\n",
        "print(\"Recall: \", best_rec - recallprev)\n",
        "print(\"F-1: \", best_f1 - f1prev)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Decision class 3\n",
            "Accurarcy:  0.8268124280782508\n",
            "Precision:  [0.89929742 0.81426107 0.78142695]\n",
            "Recall:  [0.85618729 0.83638512 0.77878104]\n",
            "f1:  [0.87721302 0.82517483 0.78010175]\n",
            "3 classes\n",
            "Accuracy:  0.832566168009206\n",
            "Depth:  59.0\n",
            "Precision:  [0.9028103  0.81792237 0.79310345]\n",
            "Recall:  [0.85953177 0.84642646 0.77878104]\n",
            "F-1:  [0.88063963 0.83193033 0.78587699]\n",
            "\n",
            "The difference\n",
            "Accuracy:  0.005753739930955182\n",
            "Precision:  [0.00351288 0.0036613  0.01167649]\n",
            "Recall:  [0.00334448 0.01004135 0.        ]\n",
            "F-1:  [0.00342661 0.00675551 0.00577524]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "g2WiQ9s7EFGF",
        "colab_type": "code",
        "outputId": "32191ca8-13d5-4da0-c521-62e2373213e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.datasets import make_classification\n",
        "clf = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42)\n",
        "clf.fit(X_train, Y_train_class)\n",
        "output = clf.predict(X_test)\n",
        "print(\"Accuracy: \", accuracy_score(Y_test_class,output))\n",
        "print(\"Precision: \", precision_score(Y_test_class,output, average=None))\n",
        "print(\"Recall: \", recall_score(Y_test_class,output, average=None))\n",
        "print(\"f1: \", f1_score(Y_test_class,output, average=None))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy:  0.8075373993095513\n",
            "Precision:  [0.92560976 0.74450812 0.87010676]\n",
            "Recall:  [0.84615385 0.92085056 0.55191874]\n",
            "f1:  [0.88410017 0.82334302 0.67541436]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "MhB7VDua_E2c",
        "colab_type": "code",
        "outputId": "c99551ff-3064-4f68-d4e8-c79c834f1aee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from scipy.stats import uniform\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "clf = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42)\n",
        "param_distributions = {\"n_estimators\": np.arange(53, 58, 1), 'max_features':[8, 10, 14, 16], 'bootstrap': [True]}\n",
        "grid_search_random = GridSearchCV(clf, param_distributions, cv=5, verbose=3, n_jobs=-1)\n",
        "grid_search_random.fit(X_train, Y_train_class)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:   17.1s\n",
            "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  1.2min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
              "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
              "            max_depth=10, max_features='auto', max_leaf_nodes=None,\n",
              "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "            min_samples_leaf=1, min_samples_split=2,\n",
              "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=None,\n",
              "            oob_score=False, random_state=42, verbose=0, warm_start=False),\n",
              "       fit_params=None, iid='warn', n_jobs=-1,\n",
              "       param_grid={'n_estimators': array([53, 54, 55, 56, 57]), 'max_features': [8, 10, 14, 16], 'bootstrap': [True]},\n",
              "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
              "       scoring=None, verbose=3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "metadata": {
        "id": "bUnUfOVWtJK-",
        "colab_type": "code",
        "outputId": "6817ff64-8b9e-42f7-c1c7-fe1975f02ab9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.datasets import make_classification\n",
        "clf = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42)\n",
        "clf.fit(X_train, Y_train_class)\n",
        "output = clf.predict(X_test)\n",
        "print(\"Old\")\n",
        "print(\"Accurarcy: \", accuracy_score(Y_test_class,output))\n",
        "prevacc = accuracy_score(Y_test_class,output)\n",
        "print(\"Precision: \", precision_score(Y_test_class,output, average=None))\n",
        "prevpre = precision_score(Y_test_class,output, average=None)\n",
        "print(\"Recall: \", recall_score(Y_test_class,output, average=None))\n",
        "prevrec = recall_score(Y_test_class,output, average=None)\n",
        "print(\"f1: \", f1_score(Y_test_class,output, average=None))\n",
        "prevf1 = f1_score(Y_test_class,output, average=None)\n",
        "print(\"\")\n",
        "print(\"Best: \")\n",
        "print(\"best estimator: \", grid_search_random.best_params_)\n",
        "print(\"best score: \", grid_search_random.best_score_)\n",
        "output = grid_search_random.predict(X_test)\n",
        "print(\"Accurarcy: \", accuracy_score(Y_test_class,output))\n",
        "newacc = accuracy_score(Y_test_class,output)\n",
        "print(\"Precision: \", precision_score(Y_test_class,output, average=None))\n",
        "newprec = precision_score(Y_test_class,output, average=None)\n",
        "print(\"Recall: \", recall_score(Y_test_class,output, average=None))\n",
        "newrecall = recall_score(Y_test_class,output, average=None)\n",
        "print(\"f1: \", f1_score(Y_test_class,output, average=None))\n",
        "newf1 = f1_score(Y_test_class,output, average=None)\n",
        "print(\"\")\n",
        "print(\"The difference of random forest\")\n",
        "print(\"Accuracy: \", newacc - prevacc)\n",
        "print(\"Precision: \", newprec - prevpre)\n",
        "print(\"Recall: \", newrecall - prevrec)\n",
        "print(\"F1: \", newf1 - prevf1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Old\n",
            "Accurarcy:  0.8075373993095513\n",
            "Precision:  [0.92560976 0.74450812 0.87010676]\n",
            "Recall:  [0.84615385 0.92085056 0.55191874]\n",
            "f1:  [0.88410017 0.82334302 0.67541436]\n",
            "\n",
            "Best: \n",
            "best estimator:  {'bootstrap': True, 'max_features': 14, 'n_estimators': 56}\n",
            "best score:  0.8616845285190247\n",
            "Accurarcy:  0.8535673187571922\n",
            "Precision:  [0.93050648 0.82644628 0.83374384]\n",
            "Recall:  [0.88071349 0.88600118 0.76410835]\n",
            "f1:  [0.90492554 0.85518814 0.79740872]\n",
            "\n",
            "The difference of random forest\n",
            "Accuracy:  0.0460299194476409\n",
            "Precision:  [ 0.00489672  0.08193816 -0.03636292]\n",
            "Recall:  [ 0.03455964 -0.03484938  0.21218962]\n",
            "F1:  [0.02082537 0.03184513 0.12199435]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "UOmC1apwr7b_",
        "colab_type": "code",
        "outputId": "73322496-5525-476e-a3f3-0b8be00a6317",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        }
      },
      "cell_type": "code",
      "source": [
        "#lets use different voting (next one)\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "named_estimators = [\n",
        "    (\"random_forest_clf\", grid_search_random), #random forest\n",
        "    (\"decision_clf\", clf_df), #decision tree\n",
        "    (\"regression_clf\", clf_regress), #SVM\n",
        "]\n",
        "voting_clf = VotingClassifier(named_estimators)\n",
        "voting_clf.fit(X_train, Y_train_class)\n",
        "print(\"Score: \", voting_clf.score(X_test, Y_test_class))\n",
        "output = voting_clf.predict(X_test)\n",
        "print(\"Accurarcy: \", accuracy_score(Y_test_class,output))\n",
        "print(\"Precision: \", precision_score(Y_test_class,output, average=None))\n",
        "print(\"Recall: \", recall_score(Y_test_class,output, average=None))\n",
        "print(\"f1: \", f1_score(Y_test_class,output, average=None))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:   15.4s\n",
            "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  1.2min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:   17.7s\n",
            "[Parallel(n_jobs=-1)]: Done 124 tasks      | elapsed:  1.4min\n",
            "[Parallel(n_jobs=-1)]: Done 284 tasks      | elapsed:  3.3min\n",
            "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:  5.7min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Score:  0.8420598388952819\n",
            "Accurarcy:  0.8420598388952819\n",
            "Precision:  [0.90804598 0.81658429 0.82802548]\n",
            "Recall:  [0.88071349 0.8783225  0.73363431]\n",
            "f1:  [0.89417091 0.84632897 0.77797726]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "wARgU69_kL8y",
        "colab_type": "code",
        "outputId": "665ca018-2fdc-4132-e825-dfa887feb956",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "cell_type": "code",
      "source": [
        "#KNN model\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "knn_clf = KNeighborsClassifier(n_jobs=-1, weights='distance', n_neighbors=4)\n",
        "knn_clf.fit(X_train, Y_train_class)\n",
        "output = knn_clf.predict(X_test)\n",
        "print(\"Accurarcy: \", accuracy_score(Y_test_class,output))\n",
        "print(\"Precision: \", precision_score(Y_test_class,output, average=None))\n",
        "print(\"Recall: \", recall_score(Y_test_class,output, average=None))\n",
        "print(\"f1: \", f1_score(Y_test_class,output, average=None))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accurarcy:  0.7491369390103567\n",
            "Precision:  [0.76890756 0.75893398 0.70904926]\n",
            "Recall:  [0.81605351 0.74010632 0.6986456 ]\n",
            "f1:  [0.79177934 0.74940191 0.70380898]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "qe2uZntRk60y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import VotingClassifier\n",
        "named_estimators = [\n",
        "    (\"random_forest_clf\", grid_search_random),\n",
        "    (\"decision_clf\", clf_df),\n",
        "    (\"KNN\", knn_clf),\n",
        "    (\"regression_clf\", clf_regress),\n",
        "]\n",
        "voting_clf = VotingClassifier(named_estimators)\n",
        "voting_clf.fit(X_train, Y_train_class)\n",
        "print(\"Score: \", voting_clf.score(X_test, Y_test_class))\n",
        "output = voting_clf.predict(X_test)\n",
        "print(\"Accurarcy: \", accuracy_score(Y_test_class,output))\n",
        "print(\"Precision: \", precision_score(Y_test_class,output, average=None))\n",
        "print(\"Recall: \", recall_score(Y_test_class,output, average=None))\n",
        "print(\"f1: \", f1_score(Y_test_class,output, average=None))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Qk85M4CiG29J",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Voting class without SVM\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "named_estimators = [\n",
        "    (\"random_forest_clf\", grid_search_random),\n",
        "    (\"decision_clf\", clf_df),\n",
        "    (\"KNN\", knn_clf),\n",
        "]\n",
        "voting_clf = VotingClassifier(named_estimators)\n",
        "voting_clf.fit(X_train, Y_train_class)\n",
        "print(\"Score: \", voting_clf.score(X_test, Y_test_class))\n",
        "output = voting_clf.predict(X_test)\n",
        "print(\"Accurarcy: \", accuracy_score(Y_test_class,output))\n",
        "print(\"Precision: \", precision_score(Y_test_class,output, average=None))\n",
        "print(\"Recall: \", recall_score(Y_test_class,output, average=None))\n",
        "print(\"f1: \", f1_score(Y_test_class,output, average=None))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dP7HizN9loiK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Voting classifier without SVM \n",
        "## We only have random forest, decision tree, and KNN\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "named_estimators = [\n",
        "    (\"random_forest_clf\", grid_search_random),\n",
        "    (\"decision_clf\", clf_df),\n",
        "    (\"KNN\", knn_clf),\n",
        "]\n",
        "#hard\n",
        "print(\"Hard\")\n",
        "voting_clf = VotingClassifier(named_estimators,voting='hard')\n",
        "voting_clf.fit(X_train, Y_train_class)\n",
        "print(\"Score: \", voting_clf.score(X_test, Y_test_class))\n",
        "output = voting_clf.predict(X_test)\n",
        "print(\"Accurarcy: \", accuracy_score(Y_test_class,output))\n",
        "print(\"Precision: \", precision_score(Y_test_class,output, average=None))\n",
        "print(\"Recall: \", recall_score(Y_test_class,output, average=None))\n",
        "print(\"f1: \", f1_score(Y_test_class,output, average=None))\n",
        "print(\"\")\n",
        "#Soft\n",
        "print(\"Soft\")\n",
        "voting_clf = VotingClassifier(named_estimators,voting='soft')\n",
        "voting_clf.fit(X_train, Y_train_class)\n",
        "print(\"Score: \", voting_clf.score(X_test, Y_test_class))\n",
        "output = voting_clf.predict(X_test)\n",
        "print(\"Accurarcy: \", accuracy_score(Y_test_class,output))\n",
        "print(\"Precision: \", precision_score(Y_test_class,output, average=None))\n",
        "print(\"Recall: \", recall_score(Y_test_class,output, average=None))\n",
        "print(\"f1: \", f1_score(Y_test_class,output, average=None))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "s4_ijfMLIRbR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Our hard voting tended to have a higher acc score with the KNN, Random Forest, and Decision Tree classifiers."
      ]
    },
    {
      "metadata": {
        "id": "_7Y5MoPWIYSi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}